<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ewezu Ngim - AI & Robotics Researcher</title>
    <style>
        :root {
            --primary-color: #3f51b5; /* Indigo */
            --accent-color: #ff9800; /* Orange/Amber */
            --text-color: #333;
            --bg-color: #f7f9fc;
            --card-bg: #fff;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
        }

        .container {
            max-width: 900px;
            margin: 40px auto;
            padding: 0 20px;
        }

        header {
            text-align: center;
            padding: 40px 0 20px;
        }

        header h1 {
            font-size: 2.5em;
            color: var(--primary-color);
            margin-bottom: 5px;
        }

        header p {
            font-size: 1.1em;
            color: #666;
            margin-top: 0;
        }

        section {
            background: var(--card-bg);
            padding: 30px;
            margin-bottom: 25px;
            border-radius: 8px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.05);
        }

        h2 {
            font-size: 1.8em;
            color: var(--primary-color);
            border-bottom: 3px solid var(--accent-color);
            padding-bottom: 5px;
            margin-top: 0;
            margin-bottom: 20px;
        }

        ul {
            list-style: none;
            padding: 0;
        }

        ul li {
            margin-bottom: 15px;
            padding-left: 20px;
            position: relative;
        }

        ul li:before {
            content: '¬ª';
            position: absolute;
            left: 0;
            color: var(--primary-color);
            font-weight: bold;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
            font-size: 0.95em;
        }

        table th, table td {
            border: 1px solid #eee;
            padding: 12px;
            text-align: left;
        }

        table th {
            background-color: #f0f2f7;
            color: var(--primary-color);
            font-weight: 600;
        }

        .contact-list a {
            color: var(--primary-color);
            text-decoration: none;
        }

        .contact-list a:hover {
            text-decoration: underline;
            color: var(--accent-color);
        }

        .skill-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 10px;
        }

        .skill-tags span {
            background-color: #e8eaf6;
            color: var(--primary-color);
            padding: 5px 10px;
            border-radius: 4px;
            font-size: 0.85em;
            font-weight: 500;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Ewezu Ngim</h1>
            [cite_start]<p>First Class Mechatronics Engineer focused on embodied AI for physical interaction and control[cite: 5].</p>
        </header>

        <section id="research-interests">
            <h2>üî¨ Research Interests & Vision</h2>
            <p>My core vision is to bridge the gap between abstract AI reasoning and physical, real-world autonomy.</p>
            <ul>
                <li>**The Critical Gap (MFMs for Robotics):** While Large Language Models (LLMs) provide a deep linguistic substrate for reasoning, their inherent lack of physical grounding prevents them from solving the most important challenge in AI: achieving true robotic autonomy in dynamic, unstructured environments. The critical gap is a reliance on purely textual data‚Äîa lossy representation that cannot holistically capture the sensory richness required for robust multimodal representation learning and cross-embodiment action. My primary objective is to bridge this gap by developing robust, **Multimodal Foundation Models (MFMs) for Robotics**.</li>
                [cite_start]<li>**Past & Present Work (LLM Reliability):** This includes First-Author work on cross-cultural LLM hallucination presented at Deep Learning Indaba[cite: 6]. [cite_start]This research involved investigating hallucination in LLMs (Llama 3.1) in various linguistic and cultural situations (Western vs. Nigerian)[cite: 60]. [cite_start]I developed a novel methodology for quantifying response uncertainty using **semantic entropy**[cite: 61].</li>
                [cite_start]<li>**Past & Present Work (Embodied Systems):** Research includes real-time, sensor-driven ML (Fall Detection) [cite: 6] [cite_start]and a thesis on **Machine Learning-Driven Fall Detection** using wearable sensors for enhanced safety[cite: 36, 53].</li>
                [cite_start]<li>**Future Focus (Robotics & Control):** I aim to master **Multimodal Data Integration**, **Reinforcement Learning (RL)**, and **Control Theory** to drive autonomous systems[cite: 7]. This specific focus on uncertainty modeling, perception beyond text, and efficient physical action aligns with this goal.</li>
            </ul>
        </section>

        <section id="publications">
            <h2>üìù Publications & Papers</h2>
            <table>
                <thead>
                    <tr>
                        <th>Title</th>
                        <th>Context/Journal</th>
                        <th>Role</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        [cite_start]<td>**Seeds, Contexts, and Tongues: Decoding the Drivers of Hallucination in Language Models** [cite: 57]</td>
                        [cite_start]<td>Presented at **Deep Learning Indaba** (2024) [cite: 59]</td>
                        [cite_start]<td>First Author [cite: 58] & Researcher</td>
                    </tr>
                    <tr>
                        [cite_start]<td>**Machine Learning-Driven Fall Detection Using Wearable Sensors for Enhanced Safety** [cite: 53]</td>
                        [cite_start]<td>*Iconic Research And Engineering Journals* (2024) [cite: 55]</td>
                        [cite_start]<td>Author [cite: 54]</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="capabilities">
            <h2>üõ†Ô∏è Professional Capabilities</h2>
            [cite_start]<p>A First-Class Mechatronics Engineer applying advanced machine learning and engineering principles[cite: 5, 35].</p>
            
            <h3>Core Technical Skills</h3>
            <div class="skill-tags">
                [cite_start]<span>Python</span> [cite: 40]
                [cite_start]<span>MATLAB</span> [cite: 40]
                [cite_start]<span>SQL</span> [cite: 40]
                [cite_start]<span>Machine Learning</span> [cite: 40]
                [cite_start]<span>Data Science</span> [cite: 41]
                <span>Deep Learning</span>
                [cite_start]<span>Natural Language Processing (NLP)</span> [cite: 83]
                [cite_start]<span>LLMs (Custom Deployment)</span> [cite: 101, 103]
                [cite_start]<span>Multilingual LLM Training (Yoruba, Igbo, Hausa)</span> [cite: 15]
                [cite_start]<span>Synthetic Data Generation</span> [cite: 19, 23]
                <span>Docker</span>
                [cite_start]<span>Git (Version Control)</span> [cite: 40]
                [cite_start]<span>RESTful Web Services (Flask, FastAPI)</span> [cite: 97, 103]
                [cite_start]<span>Custom API Endpoints</span> [cite: 12]
                [cite_start]<span>ImageJ (Advanced)</span> [cite: 40]
            </div>
        </section>

        <section id="volunteering">
            <h2>üéì Volunteering & Community Involvement</h2>
            <ul>
                [cite_start]<li>**Tutor, 3MTT DeepTech Ready Live Class (01/04/2025 - Current):** Designed and delivered advanced technical training on building end-to-end Machine Learning applications (for Data Science Nigeria) with Natural Language Processing (NLP)[cite: 82, 83].</li>
                [cite_start]<li>**Hackathon Technical Reviewer, Data Science Nigeria AI Bootcamp (20/10/2025 - Current):** Led the technical setup of the competition, including problem statements and evaluation criteria[cite: 88, 90].</li>
                [cite_start]<li>**Poster Judge, Data Science Nigeria AI Bootcamp (20/10/2025 - Current):** Judged submitted research posters based on the quality of AI models, experimental design, and data analysis[cite: 85, 86].</li>
                [cite_start]<li>**Tutor, Data Science Nigeria's AI Everyday (2024 - Current):** Actively coaching beginners in Python and helping them build Machine Learning models[cite: 78, 79].</li>
                [cite_start]<li>**Member, Afe Babalola University Developers' Committee (Current):** Mentored and tutored fellow developers, fostering a collaborative atmosphere[cite: 80, 81].</li>
            </ul>
        </section>

        <section id="awards">
            <h2>üèÜ Honours and Awards</h2>
            <ul>
                [cite_start]<li>**Founders' Award** (2018/19 - 2022/23): Won a cash prize every year during undergraduate studies from the Chancellor of my university for being a First Class student[cite: 43, 44].</li>
                [cite_start]<li>**Shell Petroleum Development Corporation (SPDC) Scholar** (2020-2023): Recognizes and rewards the academic excellence of high-performing, full-time students[cite: 48, 49].</li>
                [cite_start]<li>**Best Engineering Student in 200 Level** (18/19 Session): Awarded by the Nigerian Universities Engineering Students' Association (NUESA) with a CGPA of 4.98/5.0[cite: 45, 47].</li>
                [cite_start]<li>**First Class Honours (Magna Cum Laude)**: Graduated with a CGPA above 4.5 out of 5 in the top 10 percent of the class[cite: 35, 51].</li>
            </ul>
        </section>

        <section id="contact">
            <h2>‚úâÔ∏è Contact</h2>
            <ul class="contact-list">
                [cite_start]<li>**Email:** <a href="mailto:ewezungim348@gmail.com">ewezungim348@gmail.com</a> [cite: 3]</li>
                <li>**LinkedIn:** <a href="https://www.linkedin.com/in/ewezu-ngim-2a997a224" target="_blank">linkedin.com/in/ewezu-ngim-2a997a224</a></li>
                [cite_start]<li>**GitHub:** <a href="https://github.com/EwezuNgim" target="_blank">github.com/EwezuNgim</a> (Includes deployed projects like Customer Churn Prediction Web Service [cite: 99] [cite_start]and Chatbot as a Web Service [cite: 105])</li>
                [cite_start]<li>**Phone:** (+234) 7065695535 (Mobile) [cite: 2]</li>
            </ul>
        </section>

    </div>
</body>
</html>